{#%- set image = "gcr.io/tfdata-service/tf_custom:latest" -%#}
{#%- set port = 5050 -%#}

kind: ReplicaSet
apiVersion: apps/v1
metadata:
  name: data-service-dispatcher
spec:
  replicas: 1
  selector:
    matchLabels:
      name: data-service-dispatcher
  template:
    metadata:
      labels:
        name: data-service-dispatcher
    spec:
      nodeSelector:
        cachew.role: dispatcher
      containers:
      - name: tensorflow
        image: {{ docker_image }}
        imagePullPolicy: Always
        ports:
        - containerPort: {{ disp_port }}
        args:
        - "--port={{ disp_port }}"
        - "--is_dispatcher=true"
        - "--scaling_policy={{ scaling_policy }}"
        - "--cache_policy={{ cache_policy }}"
        - "--cache_format={{ cache_format }}"
        - "--cache_compression={{ cache_compression }}"
        - "--cache_ops_parallelism={{ cache_ops_parallelism }}"
        - "--log_dir={{ log_dir }}"
        - "--log_dumps_interval_ms={{ log_dumps_interval_ms }}"
        - "--vlog={{ vlog }}"
        - "--cache_path={{ cache_path }}"

        env:
        - name: TF_CPP_MIN_LOG_LEVEL
          value: "0"
        - name: TF_CPP_MAX_VLOG_LEVEL
          value: "{{ vlog }}"
        volumeMounts:
        - mountPath: /usr/src/app/gluster
          name: gluster
      volumes:
      - name: gluster
        glusterfs:
          endpoints: glusterfs-cluster
          path: tfdata_cache
          readOnly: false
---

{% for w in workers %}
kind: ReplicaSet
apiVersion: apps/v1
metadata:
  name: {{ w.name }}
spec:
  replicas: 1
  selector:
    matchLabels:
      name: {{ w.name }}
  template:
    metadata:
      labels:
        cachew.pod.role: worker
        name: {{ w.name }}
    spec:
      nodeSelector:
        cachew.role: worker
        kubernetes.io/hostname: {{ w.ip }}
      #affinity:
      #  podAntiAffinity:
      #    requiredDuringSchedulingIgnoredDuringExecution:
      #      - labelSelector:
      #         matchLabels:
      #            cachew.pod.role: worker
      #        topologyKey: kubernetes.io/hostname
      containers:
      - name: tensorflow
        image: {{ docker_image }}
        imagePullPolicy: Always
        ports:
        - containerPort: {{ w.port }}
        args:
        - "--port={{ w.port }}"
        - "--is_dispatcher=false"
        - "--dispatcher_address={{ dispatcher_ip }}:{{ disp_port }}"
        - "--worker_address={{ w.ip }}:{{ w.port }}"
        - "--vlog={{ vlog }}"
        - "--worker_heartbeat_interval_ms={{ worker_heartbeat_interval_ms }}"
        env:
        - name: DBK_CHECKPOINT_DIR
          value: "{{ checkpoint_dir }}"
        - name: DBK_CHECKPOINT_FREQ_MS
          value: "{{ checkpoint_freq_ms }}"
        - name: TF_CPP_MIN_LOG_LEVEL
          value: "0"
        - name: TF_CPP_MAX_VLOG_LEVEL
          value: "{{ vlog }}"
        volumeMounts:
#        - mountPath: /usr/src/app/data
#          name: data
#          readOnly: true
        - mountPath: /usr/src/app/gluster
          name: gluster
      volumes:
#      - name: data
#        persistentVolumeClaim:
#            claimName: pv-claim-training-data
#            readOnly: true
      - name: gluster
        glusterfs:
          endpoints: glusterfs-cluster
          path: tfdata_cache
          readOnly: false
      #- name: cache
      #  persistentVolumeClaim:
      #      claimName: pv-claim-cache
        #hostPath:
          #path: /training-data
          #type: Directory
        #gcePersistentDisk:
          #pdName: training-data
          #fsType: ext4
---
{% endfor %}
